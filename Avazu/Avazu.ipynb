{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('datasets/train.csv',header = 0)\n",
    "print(train_set.shape)\n",
    "print(train_set.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def dataPreprocess(dataset,test_check):\n",
    "    dataset = dataset.drop(['id','hour'],axis=1)\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for elt in ['site_id','site_domain','site_category','app_id','app_domain','app_category','device_id','device_ip','device_model']:\n",
    "        le.fit(dataset[elt])\n",
    "        dataset[elt] = le.transform(dataset[elt])\n",
    "    if test_check == 0:\n",
    "        y = dataset['click']\n",
    "        x = dataset.drop(['click'],axis = 1)\n",
    "        return x,y\n",
    "    else:\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_sets = pd.read_csv('datasets/train.csv',chunksize = 100000,header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for train_set in train_sets:\n",
    "    count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('datasets/test.csv',header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state = 52)\n",
    "i = 0\n",
    "for train_set in train_sets:\n",
    "    if i <=10:\n",
    "        x_train,y_train = dataPreprocess(train_set,0)\n",
    "        clf.fit(x_train,y_train)\n",
    "        i += 1\n",
    "    elif i <=12:\n",
    "        x_test,y_test = dataPreprocess(train_set,0)\n",
    "        y_pred = clf.predict_proba(x_test)\n",
    "        print(metrics.log_loss(y_test,y_pred))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_test = dataPreprocess(test_set,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## New Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "from math import exp,log,sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "function readData is to read the file using csv DictReader\n",
    "the D is dimension, which is the range of the weight list\n",
    "'''\n",
    "def readData(path,D):\n",
    "    for row in DictReader(open(path)):\n",
    "        ID = row['id']\n",
    "        del row['id']\n",
    "        \n",
    "        y = 0.\n",
    "        if 'click' in row:\n",
    "            if row['click'] == '1':\n",
    "                y = 1.\n",
    "            del row['click']\n",
    "            \n",
    "        row['hour'] = row['hour'][6:]\n",
    "    \n",
    "        x = []\n",
    "        for key in row:\n",
    "            value = row[key]\n",
    "            #one-hot encode with hash trick\n",
    "            index = abs(hash(key + '_'+value))%D\n",
    "            x.append(index)\n",
    "            \n",
    "        yield ID,x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class logistic_regression(object):\n",
    "    def __init__(self,alpha,L2,D,method):\n",
    "        self.alpha = alpha\n",
    "        self.L2 = L2\n",
    "        \n",
    "        self.D = D\n",
    "        self.method = method\n",
    "        \n",
    "        self.w = [0.5]*D\n",
    "        \n",
    "    def _indices(self, x):\n",
    "        method = self.method\n",
    "        yield 0\n",
    "        \n",
    "        for index in x:\n",
    "            yield index\n",
    "            \n",
    "        if method == 'interaction':\n",
    "            D = self.D\n",
    "            L = len(x)\n",
    "            x = sorted(x)\n",
    "            for i in range(1,L):\n",
    "                for j in range(i+1, L):\n",
    "                    # one-hot encode interactions with hash trick\n",
    "                    yield abs(hash(str(x[i]) + '_' + str(x[j]))) % D\n",
    "    def predict(self,x):\n",
    "        w = self.w\n",
    "        \n",
    "        # h is the h(wx) in sigmoid function\n",
    "        h = 0\n",
    "        \n",
    "        for i in self._indices(x):\n",
    "            h += w[i]\n",
    "            \n",
    "        return 1./(1.+exp(-h))\n",
    "    \n",
    "    def update(self,x,p,y):\n",
    "        # p is the prediction proba and y is the label\n",
    "        g = p-y\n",
    "        \n",
    "        alpha = self.alpha\n",
    "        L2 = self.L2\n",
    "        w = self.w\n",
    "        \n",
    "        for i in self._indices(x):\n",
    "            w[i] -= alpha*(g+ L2*w[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_loss(p, y):\n",
    "    ''' FUNCTION: Bounded logloss\n",
    "\n",
    "        INPUT:\n",
    "            p: our prediction\n",
    "            y: real answer\n",
    "\n",
    "        OUTPUT:\n",
    "            logarithmic loss of p given y\n",
    "    '''\n",
    "\n",
    "    p = max(min(p, 1. - 10e-15), 10e-15)\n",
    "    return -log(p) if y == 1. else -log(1. - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4162688258379365\n"
     ]
    }
   ],
   "source": [
    "log_learner = logistic_regression(0.01,0.**5,2**20,method = 'None')\n",
    "count = 1\n",
    "loss = 0\n",
    "for ID,x,y in readData('datasets/train.csv',2**20):\n",
    "    p = log_learner.predict(x)\n",
    "    \n",
    "    if count > 70000:\n",
    "        loss += log_loss(p,y)\n",
    "    else:\n",
    "        log_learner.update(x,p,y)\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    if count == 100001:\n",
    "        print(loss/30000)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "metrics.log_loss([0],[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-76a184368359>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreadData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'datasets/test.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_learner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0moutfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%s,%s\\n'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied"
     ]
    }
   ],
   "source": [
    "with open('datasets/submission_lr.csv', 'w') as outfile:\n",
    "    outfile.write('id,click\\n')\n",
    "    for ID, x, y in readData('datasets/test.csv', 2**20):\n",
    "        p = log_learner.predict(x)\n",
    "        outfile.write('%s,%s\\n' % (ID, str(p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [(1,'a')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 'a')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
